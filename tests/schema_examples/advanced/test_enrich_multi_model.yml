# Test multi-model enrichment (requires separate output table)
database: placeholder  # Will be replaced by test runner
default_table: documents

sql_queries:
  all_docs: |
    SELECT rowid, sha1, * FROM documents
    ORDER BY rowid

enrichments:
  - name: compare_models
    description: "Compare outputs from multiple models"
    model: ["gpt-4o-mini", "gpt-3.5-turbo"]  # Multiple models
    input:
      query: all_docs
      input_columns: ["raw_content:500"]  # Character limit
    output_table: model_comparison  # Required for multi-model
    schema:
      summary: {type: "string"}
      sentiment: {enum: ["positive", "negative", "neutral"]}
    prompt: |
      Provide a brief summary of this document and determine its sentiment.
      Summary should be one sentence only.